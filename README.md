# Rag_Ollama
Simple Rag model using Ollama via llama-index module in python.

# Usage
<ul>
  <li>Download <a target="_blank" href="https://ollama.com/download">Ollama</a>.</li>
  <li>Pull any model and edit <code>main.py</code> as per model pulled.</li>
  <li>Default model used for query is llama3.2 and for embedding nomic-embed-text.</li>
  <li>Create a folder and copy documents to be used by rag model. <a target="blank" href="https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader/">These</a> file formats are supported by llama-index <code>SimpleDirectoryReader</code>.</li>
</ul>
